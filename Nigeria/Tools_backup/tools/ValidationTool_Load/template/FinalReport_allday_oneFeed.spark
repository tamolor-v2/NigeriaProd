import org.apache.spark.sql._
val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)

hiveContext.sql("set hive.enforce.bucketing=true")
hiveContext.sql("set hive.exec.dynamic.partition.mode=nonstrict")


hiveContext.sql("insert overwrite table databasename.final_feed_report_yousef2 partition (tbl_dt)  select * from databasename.final_feed_report_yousef2 dd where dd.feed_name<>\"FeedNameValues\"")

println("Done")

 val buffer = scala.collection.mutable.ArrayBuffer(
" insert into table databasename.final_feed_report_yousef2 partition (tbl_dt) ",
" select ",
" z.feed_name feed_name,  coalesce(fcs.numberofline ,0) Hive_Records, fcs.numberoffiles    Hive_Files,  ",
" coalesce(a.numberofline ,0) Ops_Lines, a.numberoffile            Ops_Files ,   coalesce(b.numberofline,0) Rejected_Records,                        ",
" coalesce(b.numberofline,0)/coalesce(fcs.numberofline,0)*100 Rejected_Ratio, ",
" coalesce(a.numberofline,0)-(coalesce(fcs.numberofline,0)+coalesce(b.numberofline,0)) Diff ,                                       ",
" (coalesce(a.numberofline,0)-(coalesce(fcs.numberofline,0)+coalesce(b.numberofline,0)))/coalesce(a.numberofline,0)*100 Diff_Ratio ,  ",   
" case when coalesce(a.numberofline ,0) <> coalesce(fcs.numberofline ,0)+coalesce(b.numberofline,0)     ",
" then "Not Match" else "Match" end Status, ",
" coalesce(cs.numberoflineinpartition,0) Partition_Line, coalesce(fcsp.numberofuniquemsisdn,0) Unique_MSISDN, ",
" fcs.file_dt  tbl_dt ",
" from  databasename.dim_feed z ",
" left outer join ",
" (select * from databasename.feeds_count_summary_yousef s  where feed_name=\"FeedNameValues\" )fcs  ",
"  on z.feed_name = fcs.feed_name ",
"  left outer join  ",
"  (select * from databasename.Directory_filesopps_summary_yousef a  where feedname=\"FeedNameValues\") a " ,                                                        
"  on fcs.feed_name=a.feedname and fcs.file_dt=a.file_dt ",
"  left outer join             ",
"  (select * from databasename.feeds_count_rejected_summary_yousef where  feed_name  = \"FeedNameValues\") b   on ",
"  fcs.feed_name=b.feed_name and fcs.file_dt=b.tbl_dt ",
" left outer join ",
" (select  feed_name, tbl_dt, sum(numberofline) numberoflineinpartition from files_count_summary_yousef where file_dt is not null group by  feed_name, tbl_dt ) cs ",
" on fcs.feed_name = cs.feed_name and fcs.file_dt = cs.tbl_dt ",
" left outer join ",
" (select feed_name, numberofuniquemsisdn, tbl_dt from databasename.feeds_count_summary_partition_yousef) fcsp ",
" on fcs.feed_name = fcsp.feed_name and fcs.file_dt = fcsp.tbl_dt ") 
  
  
val sql=buffer.mkString(" ")
println(sql)
hiveContext.sql(sql)
exit
