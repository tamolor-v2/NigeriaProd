import org.apache.spark.sql._

val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)

hiveContext.sql("set hive.enforce.bucketing=true")
hiveContext.sql("set hive.exec.dynamic.partition.mode=nonstrict")

hiveContext.sql("insert overwrite table databasename.feeds_files_partitions partition(feed_name, file_dt) select distinct tbl_dt, 'datetime', feed_name, file_dt from databasename.files_count_summary where file_dt = targetdate and feed_name = 'FeedNameValues' ")


exit;
